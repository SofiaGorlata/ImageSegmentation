{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../input/dataa/dataA/CameraRGB/'\n",
    "mask_path = '../input/dataa/dataA/CameraSeg/'\n",
    "image_list = os.listdir(image_path)\n",
    "mask_list = os.listdir(mask_path)\n",
    "image_list = [image_path+i for i in image_list]\n",
    "mask_list = [mask_path+i for i in mask_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "img = imageio.imread(image_list[N])\n",
    "mask = imageio.imread(mask_list[N])\n",
    "mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
    "\n",
    "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
    "arr[0].imshow(img)\n",
    "arr[0].set_title('Image')\n",
    "arr[1].imshow(mask, cmap='Paired')\n",
    "arr[1].set_title('Segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = np.zeros((600, 800))\n",
    "road[np.where(mask==10)[0], np.where(mask==10)[1]]=1\n",
    "plt.imshow(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "height, width = 600, 800\n",
    "images = np.zeros((len(image_list), height, width, 3), dtype=np.int16)\n",
    "masks = np.zeros((len(image_list), height, width, 1), dtype=np.int8)\n",
    "\n",
    "for n in tqdm(range(len(image_list))):\n",
    "    img = imageio.imread(image_list[n])\n",
    "    \n",
    "    mask = imageio.imread(mask_list[n])\n",
    "    mask_road = np.zeros((600, 800, 1), dtype=np.int8)\n",
    "    mask_road[np.where(mask==10)[0], np.where(mask==10)[1]]=1\n",
    "    \n",
    "    images[n] = img\n",
    "    masks[n] = mask_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[4].reshape(600, 800, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "shuffle_ids = np.array([i for i in range(len(masks))])\n",
    "np.random.shuffle(shuffle_ids)\n",
    "train_ids = shuffle_ids[:int(len(masks)*0.8)]\n",
    "val_ids = shuffle_ids[int(len(masks)*0.8):int(len(masks)*0.8+100)]\n",
    "test_ids = shuffle_ids[int(len(masks)*0.8+100):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks = images[train_ids], masks[train_ids]\n",
    "val_images, val_masks = images[val_ids], masks[val_ids]\n",
    "test_images, test_masks = images[test_ids], masks[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, val_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
